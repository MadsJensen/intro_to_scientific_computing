{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution to assignment\n",
    "\n",
    "_By: Christopher Bailey_\n",
    "\n",
    "_Date: 15 Sep 2017_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements, function definitions and default variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, basename\n",
    "import string\n",
    "from fddhs import grep  # grep for a string in a file\n",
    "from fddhs import find  # find files matching a pattern\n",
    "\n",
    "logfile_dir = '../src/logs'  # adjust to fit where you placed the logs!\n",
    "\n",
    "# take a look at this CSV-file to determine its structure\n",
    "subject_codes = join(logfile_dir, 'subj_codes.csv')\n",
    "\n",
    "output_dir = 'assignment'  # did you remember to create it??\n",
    "output_file = join(output_dir, 'solution_Christopher_Bailey.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy-paste your mean- and median-function here:\n",
    "def mean(values):\n",
    "    return(sum(values)/len(values))\n",
    "def median(values):\n",
    "    return(sorted(values)[len(values) // 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_log_file(logfile_name, field_sep='\\t'):\n",
    "    '''Read a single log file\n",
    "    \n",
    "    The default field-separator is set to be the tab-character (\\t)\n",
    "    \n",
    "    Return the mean and median RT, and the accuracy, separately for\n",
    "    the frequent and rare categories. This is done as a list (tuple) of\n",
    "    6 return values, in the order:\n",
    "    (mean_rt_freq, median_rt_freq, accuracy_freq,\n",
    "     mean_rt_rare, median_rt_rare, accuracy_rare)\n",
    "    '''\n",
    "\n",
    "    # initialise \n",
    "    rt_freq = []\n",
    "    rt_rare = []\n",
    "    n_corr_freq = 0\n",
    "    n_corr_rare = 0\n",
    "\n",
    "    # open file and read all its lines into a list\n",
    "    fp = open(logfile_name, 'r')\n",
    "    all_lines = fp.readlines()\n",
    "    fp.close()\n",
    "\n",
    "    # hard-code the index of the stimulus/response type/number\n",
    "    idx = 5\n",
    "    \n",
    "    # loop over lines from 6th onwards\n",
    "    for line in all_lines[5:]:\n",
    "        split_line = line.split(field_sep)\n",
    "\n",
    "        # does the 3rd element of the list start with 'STIM'?\n",
    "        if split_line[2].startswith('STIM'):\n",
    "            stim_time = split_line[0]\n",
    "            cur_stim = split_line[2][idx]\n",
    "\n",
    "        else:  # nope; it starts with something other than 'STIM'\n",
    "            resp_time = split_line[0]  # replace XXX!\n",
    "            cur_resp = split_line[2][idx] # replace YYY!\n",
    "\n",
    "            # calculate RT\n",
    "            RT = int(resp_time) - int(stim_time) # formula here\n",
    "\n",
    "            # test if the current stimulus is in the `ascii_lowercase`-list\n",
    "            if cur_stim in string.ascii_lowercase:\n",
    "                rt_freq.append(RT)\n",
    "                if int(cur_resp) == 1:\n",
    "                    n_corr_freq = n_corr_freq + 1\n",
    "\n",
    "            # else test if the current stimulus is in the `digits`-list\n",
    "            elif cur_stim in string.digits:\n",
    "                rt_rare.append(RT)\n",
    "                if cur_resp == '2':\n",
    "                    n_corr_rare = n_corr_rare + 1                 \n",
    "                    \n",
    "    # freq\n",
    "    mean_rt_freq = 0.1 * mean(rt_freq)\n",
    "    median_rt_freq = 0.1 * median(rt_freq)\n",
    "    accuracy_freq = 100 * n_corr_freq / len(rt_freq)\n",
    "\n",
    "    # rare\n",
    "    mean_rt_rare = 100e-3 * mean(rt_rare)\n",
    "    median_rt_rare = 100e-3 * median(rt_rare)\n",
    "    accuracy_rare = 100 * n_corr_rare / len(rt_rare)\n",
    "\n",
    "    return(mean_rt_freq, median_rt_freq, accuracy_freq,\n",
    "           mean_rt_rare, median_rt_rare, accuracy_rare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find all the log files, place into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 logfiles found in ../src/logs\n"
     ]
    }
   ],
   "source": [
    "all_logs = find(logfile_dir, '*.log')  # what pattern/wildcard to use?\n",
    "print(len(all_logs), 'logfiles found in', logfile_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../src/logs/0010_BQR_2017-08-03.log',\n",
       " '../src/logs/0011_XYJ_2017-07-27.log',\n",
       " '../src/logs/0012_WCT_2017-06-26.log',\n",
       " '../src/logs/0013_OUP_2016-10-15.log',\n",
       " '../src/logs/0014_IKV_2017-03-05.log',\n",
       " '../src/logs/0015_HNI_2017-03-21.log',\n",
       " '../src/logs/0016_RZU_2016-09-24.log',\n",
       " '../src/logs/0018_SJI_2017-03-05.log',\n",
       " '../src/logs/0019_NDQ_2017-02-05.log',\n",
       " '../src/logs/0020_IFX_2017-07-19.log',\n",
       " '../src/logs/0021_WYK_2017-05-16.log',\n",
       " '../src/logs/0023_FCA_2017-03-09.log',\n",
       " '../src/logs/0024_ICI_2016-12-30.log',\n",
       " '../src/logs/0026_PBV_2017-07-07.log',\n",
       " '../src/logs/0027_NPC_2016-09-01.log',\n",
       " '../src/logs/0028_MQU_2017-05-04.log',\n",
       " '../src/logs/0030_MJC_2016-11-16.log',\n",
       " '../src/logs/0031_ALX_2017-01-04.log',\n",
       " '../src/logs/0032_JQA_2016-10-07.log',\n",
       " '../src/logs/0034_TRY_2016-12-16.log',\n",
       " '../src/logs/0036_ZXA_2016-10-12.log',\n",
       " '../src/logs/0037_FMC_2017-01-28.log',\n",
       " '../src/logs/0038_WOT_2017-04-29.log',\n",
       " '../src/logs/0039_DBX_2016-10-11.log',\n",
       " '../src/logs/0040_THX_2017-04-06.log',\n",
       " '../src/logs/0041_IJN_2016-09-17.log',\n",
       " '../src/logs/0042_TQL_2017-05-07.log',\n",
       " '../src/logs/0043_WOY_2016-12-25.log',\n",
       " '../src/logs/0044_GWQ_2017-08-19.log',\n",
       " '../src/logs/0045_DSA_2016-09-30.log',\n",
       " '../src/logs/0046_DKV_2016-11-26.log',\n",
       " '../src/logs/0048_MSB_2016-09-23.log',\n",
       " '../src/logs/0049_ESM_2017-01-22.log',\n",
       " '../src/logs/0050_KXP_2017-04-02.log',\n",
       " '../src/logs/0052_BFG_2017-01-17.log',\n",
       " '../src/logs/0053_YZV_2017-08-10.log',\n",
       " '../src/logs/0054_IDT_2017-06-02.log',\n",
       " '../src/logs/0055_XFK_2016-11-26.log',\n",
       " '../src/logs/0058_NKR_2017-03-23.log',\n",
       " '../src/logs/0059_KKL_2017-08-27.log']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the first file name; _subject ID_ is the first N characters of the _basename_ of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../src/logs/0010_BQR_2017-08-03.log\n",
      "0010_BQR_2017-08-03.log\n",
      "0010_BQR\n"
     ]
    }
   ],
   "source": [
    "print(all_logs[0])\n",
    "print(basename(all_logs[0]))\n",
    "print(basename(all_logs[0])[:8])  # print the first N characters of the basename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over logs, writing out results table as you go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../src/logs/subj_codes.csv'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Control'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grep(subject_codes, '0026').split(';')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = open(output_file, 'wt')\n",
    "delimiter = ','  # or whatever you like\n",
    "\n",
    "# the opposite of 'split' is 'join', which has a slightly odd syntax\n",
    "header = delimiter.join(['Subjid', 'Group', 'Cond', 'Mean RT', 'Median RT', 'Accuracy'])\n",
    "\n",
    "# write out the header-line first\n",
    "outfile.write(header + '\\n')  # remember to add the newline-character!\n",
    "\n",
    "# loop over all log files\n",
    "for log in all_logs:\n",
    "    subj_ID = basename(log)[:8]  # N=8; how many characters is the subject ID?\n",
    "\n",
    "    # Is the subject a patient or a control?\n",
    "    # first get the line that contains the subject code\n",
    "    group_line = grep(subject_codes, subj_ID)\n",
    "    # then we split the line on the delimiter (;) and take the second element\n",
    "    group = group_line.split(';')[1]\n",
    "    \n",
    "    # Now we can simply call our single-logfile function and get the results!\n",
    "    (mean_rt_freq, median_rt_freq, accuracy_freq,\n",
    "     mean_rt_rare, median_rt_rare, accuracy_rare) = read_log_file(log)\n",
    "    \n",
    "    # NB: all those variables are numbers (floats); to write them into a text file,\n",
    "    # we must first convert them into string-objects (with 2 decimal precision)\n",
    "    freq_results_str = delimiter.join(['{:.2f}'.format(mean_rt_freq),\n",
    "                                       '{:.2f}'.format(median_rt_freq),\n",
    "                                       '{:.2f}'.format(accuracy_freq)])\n",
    "    rare_results_str = delimiter.join(['{:.2f}'.format(mean_rt_rare),\n",
    "                                       '{:.2f}'.format(median_rt_rare),\n",
    "                                       '{:.2f}'.format(accuracy_rare)])\n",
    "\n",
    "    \n",
    "    # first write a line for the frequent stimuli\n",
    "    line_out = delimiter.join([subj_ID, group, 'Freq', freq_results_str])\n",
    "    outfile.write(line_out + '\\n')\n",
    "\n",
    "    # then write a line for the rare stimuli\n",
    "    line_out = delimiter.join([subj_ID, group, 'Rare', rare_results_str])\n",
    "    outfile.write(line_out + '\\n')\n",
    "\n",
    "outfile.close()  # remember to close!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional exercise 1: summary statistics\n",
    "\n",
    "Can we reproduce the paper's findings?\n",
    "\n",
    "## Install `pandas`\n",
    "\n",
    "We'll use a Python-module called [pandas](https://pandas.pydata.org) for this, which we've forgotten to include in the `environment.yaml`-file! But fear not, `conda` is your friend.\n",
    "\n",
    "* on Windows: open 'Anaconda Prompt' & execute: `activate fddhs`\n",
    "* on Mac/Linux: open a Terminal app & execute: `source activate fddhs`\n",
    "* execute the following command in the Prompt/Terminal:\n",
    "\n",
    "`conda install pandas`\n",
    "\n",
    "and answer 'y'.\n",
    "\n",
    "___You'll also need to restart `jupyter lab` for the module to be found.___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yes, this is how easy reading a csv-file _really_ can be...\n",
    "df = pd.read_csv(output_file, delimiter=delimiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subjid</th>\n",
       "      <th>Group</th>\n",
       "      <th>Cond</th>\n",
       "      <th>Mean RT</th>\n",
       "      <th>Median RT</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0010_BQR</td>\n",
       "      <td>Patient</td>\n",
       "      <td>Freq</td>\n",
       "      <td>581.16</td>\n",
       "      <td>549.3</td>\n",
       "      <td>94.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0010_BQR</td>\n",
       "      <td>Patient</td>\n",
       "      <td>Rare</td>\n",
       "      <td>658.55</td>\n",
       "      <td>639.2</td>\n",
       "      <td>85.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0011_XYJ</td>\n",
       "      <td>Control</td>\n",
       "      <td>Freq</td>\n",
       "      <td>501.09</td>\n",
       "      <td>469.2</td>\n",
       "      <td>97.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0011_XYJ</td>\n",
       "      <td>Control</td>\n",
       "      <td>Rare</td>\n",
       "      <td>583.50</td>\n",
       "      <td>557.1</td>\n",
       "      <td>88.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0012_WCT</td>\n",
       "      <td>Patient</td>\n",
       "      <td>Freq</td>\n",
       "      <td>587.64</td>\n",
       "      <td>555.9</td>\n",
       "      <td>93.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subjid    Group  Cond  Mean RT  Median RT  Accuracy\n",
       "0  0010_BQR  Patient  Freq   581.16      549.3     94.53\n",
       "1  0010_BQR  Patient  Rare   658.55      639.2     85.16\n",
       "2  0011_XYJ  Control  Freq   501.09      469.2     97.27\n",
       "3  0011_XYJ  Control  Rare   583.50      557.1     88.67\n",
       "4  0012_WCT  Patient  Freq   587.64      555.9     93.75"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 5 lines\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Mean RT</th>\n",
       "      <th>Median RT</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group</th>\n",
       "      <th>Cond</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Control</th>\n",
       "      <th>Freq</th>\n",
       "      <td>498.7750</td>\n",
       "      <td>466.405</td>\n",
       "      <td>96.1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rare</th>\n",
       "      <td>572.3250</td>\n",
       "      <td>542.625</td>\n",
       "      <td>89.0235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Patient</th>\n",
       "      <th>Freq</th>\n",
       "      <td>580.7590</td>\n",
       "      <td>542.835</td>\n",
       "      <td>94.5265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rare</th>\n",
       "      <td>681.1435</td>\n",
       "      <td>649.650</td>\n",
       "      <td>84.9605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Mean RT  Median RT  Accuracy\n",
       "Group   Cond                               \n",
       "Control Freq  498.7750    466.405   96.1080\n",
       "        Rare  572.3250    542.625   89.0235\n",
       "Patient Freq  580.7590    542.835   94.5265\n",
       "        Rare  681.1435    649.650   84.9605"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group the numerical values by Group and Condition,\n",
    "# and display the mean of each\n",
    "df.groupby(by=['Group', 'Cond']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
